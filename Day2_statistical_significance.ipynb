{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2810e57b-ca69-4336-b2d8-08c995228b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Day 2 — Statistical evaluation scaffold + results for the Random-Walk (RW) baseline\n",
    "# We will:\n",
    "# (A) Compute block-bootstrap CIs for Accuracy, Weighted-F1, Macro-F1, MCC (pooled OOS and per split)\n",
    "# (B) Prepare McNemar and Diebold–Mariano (DM) test utilities (to compare any model vs RW later)\n",
    "# (C) Run them on RW where applicable (for RW vs RW, these yield neutral results; utilities will be reused tomorrow)\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from sklearn.metrics import accuracy_score, matthews_corrcoef, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0b8f6abd-a6e3-4a7f-8256-99cb06e11560",
   "metadata": {},
   "outputs": [],
   "source": [
    "rw_preds_path = Path(\"Data/10_day_run/rw_predictions_all.csv\")\n",
    "splits_csv = Path(\"Data/10_day_run/rolling_splits.csv\")\n",
    "rw_preds = pd.read_csv(rw_preds_path)\n",
    "splits_df = pd.read_csv(splits_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a3dda131-276c-4fc2-84e0-3d76bb84d80b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure types\n",
    "rw_preds['y_true'] = rw_preds['y_true'].astype(int)\n",
    "rw_preds['y_pred'] = rw_preds['y_pred'].astype(int)\n",
    "labels_order = [-1, 0, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ac2e2977-bd21-41c8-a648-ae9c65035482",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------- (A) Moving Block Bootstrap (MBB) --------------------\n",
    "# For time series, we prefer block bootstrap to preserve local dependence.\n",
    "# We'll implement a circular MBB:\n",
    "# - Choose block length b (pooled: ~sqrt(n) ~= 11; use 10 as a clean choice)\n",
    "# - Number of blocks k = ceil(n / b); sample starts uniformly and wrap around\n",
    "\n",
    "def mbb_indices(n, block_len=10, rng=None):\n",
    "    if rng is None:\n",
    "        rng = np.random.default_rng()\n",
    "    k = int(np.ceil(n / block_len))\n",
    "    starts = rng.integers(low=0, high=n, size=k)\n",
    "    idx = []\n",
    "    for s in starts:\n",
    "        block = [(s + i) % n for i in range(block_len)]\n",
    "        idx.extend(block)\n",
    "    return np.array(idx[:n], dtype=int)\n",
    "\n",
    "def metric_tuple(y_true, y_pred):\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    mcc = matthews_corrcoef(y_true, y_pred)\n",
    "    f1_w = f1_score(y_true, y_pred, average='weighted', labels=labels_order, zero_division=0)\n",
    "    f1_macro = f1_score(y_true, y_pred, average='macro', labels=labels_order, zero_division=0)\n",
    "    return acc, f1_w, f1_macro, mcc\n",
    "\n",
    "def mbb_ci(y_true, y_pred, block_len=10, B=2000, seed=42):\n",
    "    rng = np.random.default_rng(seed)\n",
    "    n = len(y_true)\n",
    "    stats = []\n",
    "    for _ in range(B):\n",
    "        idx = mbb_indices(n, block_len=block_len, rng=rng)\n",
    "        stats.append(metric_tuple(y_true[idx], y_pred[idx]))\n",
    "    stats = np.array(stats)  # shape (B, 4)\n",
    "    # point estimate\n",
    "    pt = np.array(metric_tuple(y_true, y_pred))\n",
    "    # percentile CIs\n",
    "    lo = np.percentile(stats, 2.5, axis=0)\n",
    "    hi = np.percentile(stats, 97.5, axis=0)\n",
    "    return pt, lo, hi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f5c1063c-61a0-4a02-8330-148bcad269d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pooled OOS metrics + CIs\n",
    "y_true_all = rw_preds['y_true'].to_numpy()\n",
    "y_pred_all = rw_preds['y_pred'].to_numpy()\n",
    "pt_all, lo_all, hi_all = mbb_ci(y_true_all, y_pred_all, block_len=10, B=4000, seed=123)\n",
    "\n",
    "pooled_ci_df = pd.DataFrame({\n",
    "    \"Metric\": [\"Accuracy\", \"Weighted F1\", \"Macro F1\", \"MCC\"],\n",
    "    \"Point\": pt_all,\n",
    "    \"CI Lower (95%)\": lo_all,\n",
    "    \"CI Upper (95%)\": hi_all,\n",
    "    \"n_weeks\": [len(y_true_all)]*4\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1eb44305-409c-4756-97fd-066668e870a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Per-split CIs (smaller test size; use shorter blocks to fit, e.g., b=4)\n",
    "per_split_rows = []\n",
    "for _, r in splits_df.iterrows():\n",
    "    sid = int(r['split_id'])\n",
    "    sub = rw_preds[rw_preds['split_id'] == sid].copy()\n",
    "    y_t = sub['y_true'].to_numpy()\n",
    "    y_p = sub['y_pred'].to_numpy()\n",
    "    b = 4 if len(sub) >= 8 else max(2, len(sub)//2)\n",
    "    pt, lo, hi = mbb_ci(y_t, y_p, block_len=b, B=2000, seed=100+sid)\n",
    "    for name, p, l, h in zip([\"Accuracy\", \"Weighted F1\", \"Macro F1\", \"MCC\"], pt, lo, hi):\n",
    "        per_split_rows.append({\n",
    "            \"split_id\": sid,\n",
    "            \"Metric\": name,\n",
    "            \"Point\": p,\n",
    "            \"CI Lower (95%)\": l,\n",
    "            \"CI Upper (95%)\": h,\n",
    "            \"n_weeks\": len(sub)\n",
    "        })\n",
    "per_split_ci_df = pd.DataFrame(per_split_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3c86d326-44db-460a-bf18-b7b55a5a6ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------- (B) McNemar test utility --------------------\n",
    "# Given two models' predictions over the SAME weeks, test if their hit rates differ.\n",
    "# Returns the chi-square stat and p-value (with continuity correction).\n",
    "\n",
    "from math import fabs\n",
    "from scipy.stats import chi2\n",
    "\n",
    "def mcnemar_test(y_true, y_pred_a, y_pred_b):\n",
    "    hit_a = (y_true == y_pred_a).astype(int)\n",
    "    hit_b = (y_true == y_pred_b).astype(int)\n",
    "    n01 = int(((hit_a == 0) & (hit_b == 1)).sum())\n",
    "    n10 = int(((hit_a == 1) & (hit_b == 0)).sum())\n",
    "    if (n01 + n10) == 0:\n",
    "        return {\"n01\": n01, \"n10\": n10, \"chi2\": 0.0, \"p_value\": 1.0}\n",
    "    from math import fabs\n",
    "    from scipy.stats import chi2\n",
    "    stat = (fabs(n01 - n10) - 1)**2 / (n01 + n10)\n",
    "    p = 1 - chi2.cdf(stat, df=1)\n",
    "    return {\"n01\": n01, \"n10\": n10, \"chi2\": float(stat), \"p_value\": float(p)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bf31150e-6a4c-4e8d-a568-5d4e4be7b9c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (Sanity) RW vs RW should be null\n",
    "mcnemar_null = mcnemar_test(y_true_all, y_pred_all, y_pred_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "64adb752-923b-43f3-ab06-27cad630d93d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------- (C) Diebold–Mariano test --------------------\n",
    "# Compare loss series of two models. We'll use 0–1 loss by default.\n",
    "# We implement a standard DM with Newey–West variance (lag = h-1; here horizon h=1 → lag=0).\n",
    "\n",
    "import math\n",
    "\n",
    "def dm_test(loss_a, loss_b, h=1, lag=None):\n",
    "    d = np.array(loss_a) - np.array(loss_b)  # loss differential\n",
    "    T = len(d)\n",
    "    d_bar = d.mean()\n",
    "    if lag is None:\n",
    "        lag = h - 1  # for h=1, lag=0\n",
    "    # Newey–West HAC variance estimate\n",
    "    gamma0 = np.sum((d - d_bar)**2) / T\n",
    "    var = gamma0\n",
    "    for l in range(1, lag+1):\n",
    "        cov = np.sum((d[l:] - d_bar) * (d[:-l] - d_bar)) / T\n",
    "        w = 1 - l/(lag+1)\n",
    "        var += 2 * w * cov\n",
    "    var = var / T\n",
    "    stat = d_bar / (np.sqrt(var) + 1e-12)\n",
    "    # Two-sided p-value under asymptotic normality\n",
    "    from scipy.stats import norm\n",
    "    p = 2 * (1 - norm.cdf(abs(stat)))\n",
    "    return {\"dm_stat\": stat, \"p_value\": p, \"mean_diff\": d_bar, \"T\": T}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f6952489-1445-400e-bb99-176633dc5422",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: DM null using RW vs RW (should be neutral)\n",
    "loss_rw = (y_true_all != y_pred_all).astype(int)\n",
    "dm_null = dm_test(loss_rw, loss_rw, h=1, lag=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "92c49a49-938e-4127-b31a-7ba13ac39c1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "McNemar (RW vs RW) sanity: {'n01': 0, 'n10': 0, 'chi2': 0.0, 'p_value': 1.0}\n",
      "DM (RW vs RW) sanity: {'dm_stat': np.float64(0.0), 'p_value': np.float64(1.0), 'mean_diff': np.float64(0.0), 'T': 120}\n"
     ]
    }
   ],
   "source": [
    "print(\"McNemar (RW vs RW) sanity:\", mcnemar_null)\n",
    "print(\"DM (RW vs RW) sanity:\", dm_null)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c12645f6-fc4e-485e-bbf2-7d753e25035b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th>Point</th>\n",
       "      <th>CI Lower (95%)</th>\n",
       "      <th>CI Upper (95%)</th>\n",
       "      <th>n_weeks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Accuracy</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.450000</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Weighted F1</td>\n",
       "      <td>0.375262</td>\n",
       "      <td>0.301912</td>\n",
       "      <td>0.448265</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Macro F1</td>\n",
       "      <td>0.374870</td>\n",
       "      <td>0.294655</td>\n",
       "      <td>0.440154</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MCC</td>\n",
       "      <td>0.048128</td>\n",
       "      <td>-0.081927</td>\n",
       "      <td>0.150520</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Metric     Point  CI Lower (95%)  CI Upper (95%)  n_weeks\n",
       "0     Accuracy  0.375000        0.300000        0.450000      120\n",
       "1  Weighted F1  0.375262        0.301912        0.448265      120\n",
       "2     Macro F1  0.374870        0.294655        0.440154      120\n",
       "3          MCC  0.048128       -0.081927        0.150520      120"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pooled_ci_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e0752060-7e59-4d62-ad7a-30bf40a41483",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>split_id</th>\n",
       "      <th>Metric</th>\n",
       "      <th>Point</th>\n",
       "      <th>CI Lower (95%)</th>\n",
       "      <th>CI Upper (95%)</th>\n",
       "      <th>n_weeks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Accuracy</td>\n",
       "      <td>0.304348</td>\n",
       "      <td>0.130435</td>\n",
       "      <td>0.521739</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Weighted F1</td>\n",
       "      <td>0.313043</td>\n",
       "      <td>0.130637</td>\n",
       "      <td>0.550741</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Macro F1</td>\n",
       "      <td>0.207407</td>\n",
       "      <td>0.089717</td>\n",
       "      <td>0.314286</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>MCC</td>\n",
       "      <td>-0.270092</td>\n",
       "      <td>-0.592428</td>\n",
       "      <td>0.004119</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>Accuracy</td>\n",
       "      <td>0.304348</td>\n",
       "      <td>0.130435</td>\n",
       "      <td>0.521739</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   split_id       Metric     Point  CI Lower (95%)  CI Upper (95%)  n_weeks\n",
       "0         1     Accuracy  0.304348        0.130435        0.521739       23\n",
       "1         1  Weighted F1  0.313043        0.130637        0.550741       23\n",
       "2         1     Macro F1  0.207407        0.089717        0.314286       23\n",
       "3         1          MCC -0.270092       -0.592428        0.004119       23\n",
       "4         2     Accuracy  0.304348        0.130435        0.521739       23"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "per_split_ci_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "23323010-0dc5-4c52-b283-a83df2d80052",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Additional diagnostics for your write-up: class mix and confusion matrix for RW pooled OOS\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "y_true_all = rw_preds['y_true'].astype(int).to_numpy()\n",
    "y_pred_all = rw_preds['y_pred'].astype(int).to_numpy()\n",
    "\n",
    "labels_order = [-1, 0, 1]\n",
    "cm = confusion_matrix(y_true_all, y_pred_all, labels=labels_order)\n",
    "support = pd.Series(y_true_all).value_counts().reindex(labels_order).fillna(0).astype(int)\n",
    "\n",
    "cm_df = pd.DataFrame(cm, index=[f\"True {c}\" for c in labels_order], columns=[f\"Pred {c}\" for c in labels_order])\n",
    "support_df = pd.DataFrame({\"Class\": labels_order, \"Support\": support.values})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d7339e8f-3441-4b43-b605-4588709dba8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pred -1</th>\n",
       "      <th>Pred 0</th>\n",
       "      <th>Pred 1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>True -1</th>\n",
       "      <td>11</td>\n",
       "      <td>8</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True 0</th>\n",
       "      <td>5</td>\n",
       "      <td>18</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True 1</th>\n",
       "      <td>15</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Pred -1  Pred 0  Pred 1\n",
       "True -1       11       8      11\n",
       "True 0         5      18      20\n",
       "True 1        15      16      16"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2c29bb4f-2be8-4376-9329-249734738c70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class</th>\n",
       "      <th>Support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Class  Support\n",
       "0     -1       30\n",
       "1      0       43\n",
       "2      1       47"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "support_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c3def938-62e2-43fb-8789-411e1ea68454",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model_vs_rw(model_preds_csv, block_len=10, B=4000, seed=2025):\n",
    "    model_df = pd.read_csv(model_preds_csv)\n",
    "    # Align on Week & split_id to the RW OOS set\n",
    "    merged = pd.merge(rw_preds[['Week','split_id','y_true','y_pred']].rename(columns={'y_pred':'y_pred_rw'}),\n",
    "                      model_df[['Week','split_id','y_pred']].rename(columns={'y_pred':'y_pred_model'}),\n",
    "                      on=['Week','split_id'], how='inner')\n",
    "    y_true = merged['y_true'].astype(int).to_numpy()\n",
    "    y_rw = merged['y_pred_rw'].astype(int).to_numpy()\n",
    "    y_model = merged['y_pred_model'].astype(int).to_numpy()\n",
    "    \n",
    "    # Pooled metrics for the model + CIs\n",
    "    pt, lo, hi = mbb_ci(y_true, y_model, block_len=block_len, B=B, seed=seed)\n",
    "    pooled_ci = pd.DataFrame({\n",
    "        \"Metric\": [\"Accuracy\", \"Weighted F1\", \"Macro F1\", \"MCC\"],\n",
    "        \"Point\": pt,\n",
    "        \"CI Lower (95%)\": lo,\n",
    "        \"CI Upper (95%)\": hi,\n",
    "        \"n_weeks\": [len(y_true)]*4\n",
    "    })\n",
    "    \n",
    "    # McNemar: model vs RW on hits\n",
    "    mc = mcnemar_test(y_true, y_model, y_rw)\n",
    "    \n",
    "    # DM test: 0-1 loss series\n",
    "    loss_model = (y_true != y_model).astype(int)\n",
    "    loss_rw = (y_true != y_rw).astype(int)\n",
    "    dm = dm_test(loss_model, loss_rw, h=1, lag=0)\n",
    "    \n",
    "    # Package\n",
    "    bundle = {\n",
    "        \"pooled_ci\": pooled_ci,\n",
    "        \"mcnemar\": mc,\n",
    "        \"dm\": dm,\n",
    "        \"aligned_rows\": len(merged)\n",
    "    }\n",
    "    return bundle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b246a2d-8efa-4315-a9d7-2bee7748f405",
   "metadata": {},
   "source": [
    "Headline numbers (pooled OOS, 95% CI):\n",
    "\n",
    "Accuracy: 0.375 (CI: 0.30–0.45)\n",
    "\n",
    "Weighted-F1: 0.375 (CI: 0.302–0.448)\n",
    "\n",
    "Macro-F1: 0.375 (CI: 0.295–0.440)\n",
    "\n",
    "MCC: 0.048 (CI: −0.082–0.151)\n",
    "\n",
    "Interpretation for the thesis\n",
    "The random-walk accuracy sits around 37–38% across 120 weeks on the 3-class task, with a fairly wide CI.\n",
    "\n",
    "MCC’s CI straddles zero, which is exactly what you expect from a no-skill baseline: no reliable association with the true directions.\n",
    "\n",
    "This is useful: it gives you a calibrated yardstick. Any model you present should beat these intervals, and you’ll be able to show that the lift is both statistically and economically meaningful."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbf8cafa-1216-49e8-969b-620eb48e2616",
   "metadata": {},
   "source": [
    "2) Per-split variability (with CIs)\n",
    "Per split, test windows are ~23 weeks (last block ~5 weeks), so CIs are wider and some splits dip negative on MCC. That swinginess is expected given small n and the 3-class set-up; it’s the main reason we’re doing rolling-origin rather than a single hold-out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b138cae-f2eb-439d-8b0f-30df0fd7615d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (fusionnet)",
   "language": "python",
   "name": "fusionnet"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
