{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ef54598-df15-4186-8166-0df68a5be9f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from google.cloud import storage\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from datasets import load_dataset, Dataset\n",
    "import torch\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc25df84-a11c-4f8c-8f73-92a97c51e376",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"HF_DATASETS_CACHE\"] = \"/mnt/disks/data/hf_cache\"\n",
    "os.environ[\"HF_DATASETS_OFFLINE\"] = \"1\"  # Optional: if you're only working locally\n",
    "os.environ[\"TRANSFORMERS_CACHE\"] = \"/mnt/disks/data/transformers_cache\"\n",
    "os.environ[\"TMPDIR\"] = \"/mnt/disks/data/tmp\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc353674-0f79-43ef-a010-6d43447b5e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detect number of GPUs\n",
    "gpus = torch.cuda.device_count()\n",
    "print(f\"Number of GPUs available: {gpus}\")\n",
    "print(torch.cuda.get_device_name(0))\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab2ea2ba-a1a8-41b4-afbe-88c17cba3923",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "BUCKET_NAME = \"diss_market_data\"\n",
    "MODEL_PREFIX = \"finbert-finetuned_onlyfilings/\"\n",
    "MODEL_LOCAL_DIR = \"finbert_onlyfilings\"\n",
    "# DATASET_PREFIX = \"edgar-corpus-full/\"\n",
    "DATASET_LOCAL_DIR = \"Data/10K_combined_dataset.csv\"\n",
    "# CIK_PATH = \"./Data/FILINGS_METADATA.csv\"\n",
    "OUTPUT_CSV_PATH = \"./Data/aggregated_sentiment_scores.csv\"\n",
    "SECTIONS = [\"section_1A\", \"section_7\"]\n",
    "# YEARS = set([\"2006\",\"2007\",\"2008\",\"2009\",\"2010\",\"2011\",\"2012\",\"2013\"])\n",
    "CHUNK_SIZE = 512\n",
    "CHUNK_STRIDE = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba91ac54-ffb5-478e-8636-454971d55221",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------ Load Tickers ---------------------------\n",
    "# metadata = pd.read_csv(CIK_PATH)\n",
    "# CIK_SET = set(metadata['CIK'].astype(str).str.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e203a9d-f2dc-45b7-9267-7cf00f809b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------- GCS Download Helpers ---------------------\n",
    "def download_from_gcs(bucket_name, prefix, local_dir):\n",
    "    client = storage.Client()\n",
    "    bucket = client.bucket(bucket_name)\n",
    "    blobs = bucket.list_blobs(prefix=prefix)\n",
    "\n",
    "    for blob in blobs:\n",
    "        if blob.name.endswith('/'):  # Skip folders\n",
    "            continue\n",
    "        rel_path = os.path.relpath(blob.name, prefix)\n",
    "        local_path = os.path.join(local_dir, rel_path)\n",
    "        os.makedirs(os.path.dirname(local_path), exist_ok=True)\n",
    "        blob.download_to_filename(local_path)\n",
    "\n",
    "# Download model if not present\n",
    "if not os.path.exists(os.path.join(MODEL_LOCAL_DIR, \"pytorch_model.bin\")):\n",
    "    download_from_gcs(BUCKET_NAME, MODEL_PREFIX, MODEL_LOCAL_DIR)\n",
    "\n",
    "# Download dataset if not present\n",
    "# if not os.listdir(DATASET_LOCAL_DIR):\n",
    "#     download_from_gcs(BUCKET_NAME, DATASET_PREFIX, DATASET_LOCAL_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e73bb7d4-b670-43a8-a091-79ca1213171e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------ Load Model -----------------------------\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_LOCAL_DIR)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL_LOCAL_DIR).to(DEVICE)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03da9a46-a9d6-4916-bc93-b598ffc3ed47",
   "metadata": {},
   "source": [
    "# ---------------------- Sentiment Logic --------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53f0b3a9-0466-43cc-8bb6-84e83056ec27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_section_chunks(text, max_len=512, stride=128):\n",
    "    tokens = tokenizer(text, truncation=False, padding=False, return_tensors='pt')['input_ids'][0]\n",
    "    chunks = [tokens[i:i+max_len] for i in range(0, len(tokens), max_len - stride)]\n",
    "    return [tokenizer.decode(chunk, skip_special_tokens=True) for chunk in chunks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bee31288-b4b1-4921-b605-9b93a078f161",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batched_predict(chunks):\n",
    "    inputs = tokenizer(chunks, padding='max_length', truncation=True, max_length=512, return_tensors=\"pt\")\n",
    "    inputs = {k: v.to(DEVICE) for k, v in inputs.items()}  # ✅ ensure proper device\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    probs = torch.nn.functional.softmax(outputs.logits, dim=1).cpu().numpy()\n",
    "    labels = probs.argmax(axis=1)\n",
    "    label_map = ['negative', 'neutral', 'positive']\n",
    "    results = []\n",
    "    for i, score in enumerate(probs):\n",
    "        label = label_map[labels[i]]\n",
    "        scaled_score = max(score) * (1 if label == 'positive' else -1 if label == 'negative' else 0)\n",
    "        results.append((scaled_score, label))\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff7ea32e-7e80-4a07-8fc5-a76f0dc608a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = [\"train\", \"test\", \"validation\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ac31b11-b99d-42be-be8f-8b6ff080a634",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(DATASET_LOCAL_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1909efd-b4ff-4efa-9912-36adff02612c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # assume dataset['train'] is a list of dicts all sharing the same keys\n",
    "# keys = dataset['train'][0].keys()\n",
    "\n",
    "# for key in keys:\n",
    "#     for example in dataset['train']:\n",
    "#         val = example.get(key)\n",
    "#         # skip empty strings (and non‑string values, if you only care about str)\n",
    "#         if isinstance(val, str) and val != '':\n",
    "#             print(f\"{key!r}: {val!r}\")\n",
    "#             break\n",
    "#     else:\n",
    "#         # no non-empty string found for this key\n",
    "#         print(f\"{key!r}: (all values empty)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "705b0852-4387-41e9-90f0-e02de22e9643",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_record(record):\n",
    "    cik = record.get('cik', '').strip()\n",
    "    year = record.get('year', '')\n",
    "\n",
    "    if cik not in CIK_SET or year not in YEARS:\n",
    "        return []\n",
    "    \n",
    "    results = []\n",
    "    for section in SECTIONS:\n",
    "        # print(section)\n",
    "        text = record.get(section, '').strip()\n",
    "        if not text:\n",
    "            # print(f'No Text: {text} :: {section}')\n",
    "            continue\n",
    "\n",
    "        chunks = get_section_chunks(text)\n",
    "        if not chunks:\n",
    "            continue\n",
    "\n",
    "        sentiments = batched_predict(chunks)\n",
    "        scores = [s for s, _ in sentiments]\n",
    "        labels = [l for _, l in sentiments]\n",
    "\n",
    "        avg_score = sum(scores) / len(scores)\n",
    "        majority_label = max(set(labels), key=labels.count)\n",
    "\n",
    "        results.append({\n",
    "            'CIK': cik,\n",
    "            'Type': '10K',\n",
    "            'Year': year,\n",
    "            'Section': section,\n",
    "            'Sentiment Score': avg_score,\n",
    "            'Sentiment Label': majority_label\n",
    "        })\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd23a86e-47f8-45a8-8cd7-b3468f0a37f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------ Load & Stream Dataset -------------------------\n",
    "splits = [\"train\", \"test\", \"validation\"]\n",
    "all_results = []\n",
    "\n",
    "for split in splits:\n",
    "    ds = dataset[split]\n",
    "    for record in tqdm(ds, desc=f\"Processing {split}\"):\n",
    "        results = process_record(record)\n",
    "        all_results.extend(results)\n",
    "        if len(all_results) == 1:\n",
    "            print(all_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee13cebd-1fa4-4492-aa27-cfeb2ff0d5db",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(all_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02b852ad-5375-4004-b335-bc84aa761b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------ Save Results ----------------------------------\n",
    "df = pd.DataFrame(all_results)\n",
    "df.to_csv(OUTPUT_CSV_PATH, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2949ed67-9429-48bc-bf27-a1681ec51a6f",
   "metadata": {},
   "source": [
    "## 10-Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4407461b-6b1b-43bf-854e-5b51856c26d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "DATASET_LOCAL_DIR = \"./Data/10Q_combined_dataset.csv\"\n",
    "OUTPUT_CSV_PATH = \"./Data/aggregated_sentiment_scores_10Q.csv\"\n",
    "SECTIONS = [\"part_1_item_2\", \"part_2_item_1A\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08862e45-aca3-4a62-8f04-2868e957267a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Dataset\n",
    "dataset = pd.read_csv(DATASET_LOCAL_DIR)\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2adff18a-8b9f-4810-b882-30e7763e8d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66f7d309-98f5-413b-aa60-201718e118aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------- Main Scoring Function for 10-Q, 8-K and 10-K -----------\n",
    "def process_dataframe(df):\n",
    "    results = []\n",
    "\n",
    "    for _, row in tqdm(df.iterrows(), total=len(df)):\n",
    "        cik = str(row['cik']).strip()\n",
    "        filing_date = row['filing_date']\n",
    "        filing_type = row['filing_type']\n",
    "\n",
    "        for section in SECTIONS:\n",
    "            text = row.get(section, '')\n",
    "            if not isinstance(text, str) or not text.strip():\n",
    "                continue\n",
    "\n",
    "            chunks = get_section_chunks(text)\n",
    "            if not chunks:\n",
    "                continue\n",
    "\n",
    "            sentiments = batched_predict(chunks)\n",
    "            scores = [s for s, _ in sentiments]\n",
    "            labels = [l for _, l in sentiments]\n",
    "\n",
    "            avg_score = sum(scores) / len(scores)\n",
    "            majority_label = max(set(labels), key=labels.count)\n",
    "\n",
    "            results.append({\n",
    "                'CIK': cik,\n",
    "                'Type': filing_type,\n",
    "                'Filing Date': filing_date,\n",
    "                'Section': section,\n",
    "                'Sentiment Score': avg_score,\n",
    "                'Sentiment Label': majority_label\n",
    "            })\n",
    "\n",
    "    return pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f59b2070-d4e6-4c8e-8f17-ac36744bcde2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------- Calling Function -----------\n",
    "results_10q = process_dataframe(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "286d1e0e-b439-414b-b7a2-9423da821888",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_10q.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b64c74b-ff58-4948-9eec-b9474731732a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------- Saving Result -----------\n",
    "results_10q.to_csv(OUTPUT_CSV_PATH, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45711d76-c3bb-4bb0-aeb4-93211d72000c",
   "metadata": {},
   "source": [
    "## 8-K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9431fd1b-e8e7-4fd9-9cef-8ed6fbcecd9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "DATASET_LOCAL_DIR = \"./Data/8K_combined_dataset.csv\"\n",
    "OUTPUT_CSV_PATH = \"./Data/aggregated_sentiment_scores_8K.csv\"\n",
    "SECTIONS = [\n",
    "    \"item_2.02\",  # Results of Operations and Financial Condition\n",
    "    \"item_8.01\",  # Other Events\n",
    "    \"item_1.01\",  # Entry into a Material Definitive Agreement\n",
    "    \"item_2.01\",  # Completion of Acquisition or Disposition of Assets\n",
    "    \"item_5.02\",  # Departure/Election of Directors or Officers; Compensatory Arrangements\n",
    "    \"item_2.05\",  # Costs Associated with Exit or Disposal Activities\n",
    "    \"item_1.03\",  # Bankruptcy or Receivership\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46487237-1a41-4290-a25d-96ae57ea2e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Dataset\n",
    "dataset = pd.read_csv(DATASET_LOCAL_DIR)\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f4c2df7-8d15-48a1-991f-d85709ca5fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4796d1bd-3e01-4659-b2c5-776806c014d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------- Calling Function -----------\n",
    "results_8k = process_dataframe(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b08d7e19-a107-48f4-aa34-e60db47ba0f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------- Saving Result -----------\n",
    "results_8k.to_csv(OUTPUT_CSV_PATH, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3fa64b2-009b-4fb3-a796-f378b86b5739",
   "metadata": {},
   "source": [
    "# 10-K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac3ae1ea-7785-4f31-915a-790c2de27357",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "DATASET_LOCAL_DIR = \"./Data/10K_combined_dataset.csv\"\n",
    "OUTPUT_CSV_PATH = \"./Data/aggregated_sentiment_scores_10K_new.csv\"\n",
    "SECTIONS = [\"item_1A\", \"item_7\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98b70013-01a4-4ddd-8b06-56b9d2b2bf87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Dataset\n",
    "dataset = pd.read_csv(DATASET_LOCAL_DIR)\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b65b7100-d421-43b7-8327-9cea85f4a141",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------- Calling Function -----------\n",
    "results_10k = process_dataframe(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eeee331-d9e9-41dd-86dc-f93c10a9b70e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------- Saving Result -----------\n",
    "results_8k.to_csv(OUTPUT_CSV_PATH, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c77bb13a-84ad-4643-af1c-584591fed0fb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (fusionnet)",
   "language": "python",
   "name": "fusionnet"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
