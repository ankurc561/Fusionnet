{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b3b71cf8-e387-4533-8803-e0679dba3541",
   "metadata": {
    "id": "b3b71cf8-e387-4533-8803-e0679dba3541"
   },
   "source": [
    "## Gemini Prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d14a5bb-9e91-4cce-ab57-3d101bf09405",
   "metadata": {
    "id": "1d14a5bb-9e91-4cce-ab57-3d101bf09405"
   },
   "outputs": [],
   "source": [
    "from datasets import load_from_disk\n",
    "from transformers import AutoTokenizer\n",
    "from google.cloud import bigquery\n",
    "from google import genai\n",
    "from tenacity import retry, stop_after_attempt, wait_random_exponential, retry_if_exception_type\n",
    "from google.api_core.exceptions import ResourceExhausted, ServiceUnavailable\n",
    "from tqdm.auto import tqdm\n",
    "from datetime import datetime, timezone\n",
    "import re\n",
    "import json\n",
    "import time\n",
    "from itertools import islice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aef60a38-cddd-41de-8208-5998ce3096d8",
   "metadata": {
    "id": "aef60a38-cddd-41de-8208-5998ce3096d8"
   },
   "outputs": [],
   "source": [
    "# === 1. Configuration ===\n",
    "PROJECT_ID   = \"bamboo-mercury-462915-f0\"\n",
    "BQ_DATASET   = \"edgar_sentiment\"\n",
    "BQ_TABLE     = \"filing_scores\"\n",
    "REGION_MODEL = \"us-central1\"\n",
    "BQ_REGION    = \"europe-west2\"\n",
    "MAX_FILES    = 1000         # process at most 1 000 filings\n",
    "MAX_TOKENS   = 512\n",
    "STRIDE       = 50           # overlap between chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d85b4b6f-03f9-4328-8230-c90b71482a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only label these two sections\n",
    "TARGET_SECTIONS = {\"section_7\", \"section_1A\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d08b0fd-1397-462c-857d-847e928602d4",
   "metadata": {
    "id": "8d08b0fd-1397-462c-857d-847e928602d4"
   },
   "outputs": [],
   "source": [
    "# === 2. Initialize clients & resources ===\n",
    "bq = bigquery.Client(project=PROJECT_ID)\n",
    "genai_client = genai.Client(vertexai=True, project=PROJECT_ID, location=REGION_MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "014386c8-d615-4c53-849f-9ba36222be38",
   "metadata": {
    "id": "014386c8-d615-4c53-849f-9ba36222be38",
    "outputId": "a4f4d9da-3256-4770-eedb-781d3551accc"
   },
   "outputs": [],
   "source": [
    "# Ensure BigQuery dataset exists\n",
    "ds_ref = bigquery.Dataset(f\"{PROJECT_ID}.{BQ_DATASET}\")\n",
    "ds_ref.location = BQ_REGION\n",
    "bq.create_dataset(ds_ref, exists_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a93e09f-ec76-4206-b961-36c87929c503",
   "metadata": {
    "id": "7a93e09f-ec76-4206-b961-36c87929c503",
    "outputId": "6b9a6295-7b42-4636-8592-1b8735c5b28e"
   },
   "outputs": [],
   "source": [
    "# === 2. Prepare the target table ===\n",
    "table_id = f\"{PROJECT_ID}.{BQ_DATASET}.{BQ_TABLE}\"\n",
    "schema = [\n",
    "    bigquery.SchemaField(\"blob_name\", \"STRING\"),\n",
    "    bigquery.SchemaField(\"cik\", \"STRING\"),\n",
    "    bigquery.SchemaField(\"year\", \"STRING\"),\n",
    "    bigquery.SchemaField(\"section\", \"STRING\"),\n",
    "    bigquery.SchemaField(\"chunk_text\", \"STRING\"),\n",
    "    bigquery.SchemaField(\"sentiment_label\", \"STRING\"),\n",
    "    bigquery.SchemaField(\"sentiment_score\", \"FLOAT\"),\n",
    "]\n",
    "table = bigquery.Table(table_id, schema=schema)\n",
    "bq_client.create_table(table, exists_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3262b62-c0b7-46f3-9b7b-6c752d813501",
   "metadata": {
    "id": "c3262b62-c0b7-46f3-9b7b-6c752d813501"
   },
   "outputs": [],
   "source": [
    "# === 3. FinBERT tokenizer for 512-token chunks ===\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"yiyanghkust/finbert-tone\")\n",
    "\n",
    "def token_chunker(text: str):\n",
    "    enc = tokenizer(\n",
    "        text,\n",
    "        return_overflowing_tokens=True,\n",
    "        truncation=True,\n",
    "        max_length=MAX_TOKENS,\n",
    "        stride=STRIDE\n",
    "    )\n",
    "    for toks in enc[\"input_ids\"]:\n",
    "        yield tokenizer.decode(toks, skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "575e9e95-d4d4-4b5e-8943-1669376a75ca",
   "metadata": {
    "colab": {
     "referenced_widgets": [
      "dee055228f9f4fa195daa19cbf5e085c"
     ]
    },
    "id": "575e9e95-d4d4-4b5e-8943-1669376a75ca",
    "outputId": "55d13635-ab07-4f9a-d91f-570abb26893c"
   },
   "outputs": [],
   "source": [
    "# === 4. Ingest & upload chunks for every section ===\n",
    "# Downlaod from cloud\n",
    "ds = load_from_disk(\"edgar-corpus-full\")\n",
    "ds = ds['train']\n",
    "# shuffle once\n",
    "ds = ds.shuffle(seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de8fe88a-9568-49e1-924f-b06fe10312ed",
   "metadata": {
    "id": "de8fe88a-9568-49e1-924f-b06fe10312ed"
   },
   "outputs": [],
   "source": [
    "def analyze_sentiment(text: str) -> str:\n",
    "    prompt = f\"\"\"\n",
    "You are a financial analyst. Respond **only** with JSON matching this schema:\n",
    "{{\"sentiment\":\"Positive|Neutral|Negative\",\"score\":float,\"explanation\":string}}\n",
    "\n",
    "Excerpt:\n",
    "{text}\n",
    "\"\"\"\n",
    "    resp = genai_client.models.generate_content(\n",
    "        model=\"gemini-2.0-flash\",\n",
    "        contents=[prompt]\n",
    "    )\n",
    "    return resp.text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6109c64-da0e-45da-8bc9-1878a2efae57",
   "metadata": {
    "id": "a6109c64-da0e-45da-8bc9-1878a2efae57"
   },
   "outputs": [],
   "source": [
    "# === 5. Parser for Gemini JSON response ===\n",
    "def parse_gemini(resp: str):\n",
    "    try:\n",
    "        obj = json.loads(resp)\n",
    "        return obj.get(\"sentiment\", \"Unknown\"), obj.get(\"score\", None)\n",
    "    except json.JSONDecodeError:\n",
    "        # fallback to regex\n",
    "        sent_m = re.search(r'\"sentiment\"\\s*:\\s*\"(\\w+)\"', resp)\n",
    "        score_m = re.search(r'\"score\"\\s*:\\s*([-+]?\\d*\\.?\\d+)', resp)\n",
    "        label = sent_m.group(1) if sent_m else \"Unknown\"\n",
    "        score = float(score_m.group(1)) if score_m else None\n",
    "        return label, score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a407f0cb-08ba-411d-9ad4-488c2343e007",
   "metadata": {
    "id": "a407f0cb-08ba-411d-9ad4-488c2343e007"
   },
   "outputs": [],
   "source": [
    "# === 7. Fetch already-processed blob_names from BQ ===\n",
    "processed = {\n",
    "    row.blob_name\n",
    "    for row in bq.query(\n",
    "        f\"SELECT DISTINCT blob_name FROM `{table_id}`\"\n",
    "    ).result()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9377f6e5-a2ea-47ba-a8d3-b6998ea2ca7c",
   "metadata": {
    "colab": {
     "referenced_widgets": [
      "426c80e056ec4fb5bdd8985459aa9f8a"
     ]
    },
    "id": "9377f6e5-a2ea-47ba-a8d3-b6998ea2ca7c",
    "outputId": "8e91ff61-29f5-479c-c03f-16c12b5ce05b"
   },
   "outputs": [],
   "source": [
    "# === 8. Main loop: chunk → label → insert ===\n",
    "count = 0\n",
    "for idx, row in tqdm(\n",
    "    islice(enumerate(ds), MAX_FILES),\n",
    "    total=MAX_FILES,\n",
    "    desc=\"Filings\",\n",
    "    unit=\"file\"\n",
    "):\n",
    "    cik  = row[\"cik\"]\n",
    "    year = row[\"year\"]\n",
    "    for section in TARGET_SECTIONS:\n",
    "        text = row.get(section) or \"\"\n",
    "        for cidx, chunk in enumerate(token_chunker(text)):\n",
    "            blob_name = f\"{cik}_{year}_{section}_{idx}_{cidx}\"\n",
    "            if blob_name in processed:\n",
    "                continue\n",
    "\n",
    "            # call Gemini with retries\n",
    "            try:\n",
    "                resp = analyze_sentiment(chunk)\n",
    "            except Exception as e:\n",
    "                print(f\"[ERROR] Gemini failed for {blob_name}: {e}\")\n",
    "                continue\n",
    "\n",
    "            label, score = parse_gemini(resp)\n",
    "\n",
    "            # prepare row\n",
    "            row_out = {\n",
    "                \"blob_name\":       blob_name,\n",
    "                \"cik\":             cik,\n",
    "                \"year\":            year,\n",
    "                \"section\":         section,\n",
    "                \"chunk_text\":      chunk,\n",
    "                \"sentiment_label\": label,\n",
    "                \"sentiment_score\": score,\n",
    "            }\n",
    "\n",
    "            # insert with dedupe via row_ids\n",
    "            errors = bq.insert_rows_json(\n",
    "                table_id,\n",
    "                [row_out],\n",
    "                row_ids=[blob_name]\n",
    "            )\n",
    "            if errors:\n",
    "                print(f\"[BQ ERROR] {blob_name}: {errors}\")\n",
    "\n",
    "    count += 1\n",
    "\n",
    "print(f\"✅ Completed sentiment labeling for {count} filings.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1764a82-10eb-46d9-8c6c-d3aa57f2935b",
   "metadata": {
    "id": "e1764a82-10eb-46d9-8c6c-d3aa57f2935b"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "environment": {
   "kernel": "conda-env-pytorch-pytorch",
   "name": "workbench-notebooks.m130",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m130"
  },
  "kernelspec": {
   "display_name": "PyTorch 1-13 (Local)",
   "language": "python",
   "name": "conda-env-pytorch-pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
